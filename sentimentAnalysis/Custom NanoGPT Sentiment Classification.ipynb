{"cells":[{"cell_type":"markdown","metadata":{"id":"UeHYe3lAUmig"},"source":["# Imports and Global Variables"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tcxBqUHY2wQG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745523994542,"user_tz":240,"elapsed":2313,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}},"outputId":"d1e933b9-1ddf-482b-8233-200eb5194900"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n","Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n","Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n","Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n","Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n","Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"]}],"source":["!pip install emoji contractions tiktoken wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hl_6s8dTOnJz","outputId":"f5041e95-3c4c-4753-96df-343b8fc35f46","executionInfo":{"status":"ok","timestamp":1745523995076,"user_tz":240,"elapsed":533,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/AdvDeepLearning/SentimentAnalysis/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hA73SYjxN_29","outputId":"a6daea97-bb0b-4e4b-982e-a8f7d34cf635","executionInfo":{"status":"ok","timestamp":1745524000120,"user_tz":240,"elapsed":5042,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from google.colab import userdata\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import seaborn as sns\n","import pandas as pd\n","import numpy\n","import os\n","\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","import contractions\n","import string\n","import emoji\n","import re\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from model import GPT, GPTConfig, Block, LayerNorm # Don't forget to upload model.py to /content | https://github.com/karpathy/nanoGPT/blob/master/model.py\n","from transformers import BertTokenizer\n","import torch.nn.functional as F\n","import torch.nn as nn\n","import scipy.sparse\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import tiktoken\n","import torch\n","import wandb\n","import math\n","import os\n","\n","\n","### Global Variables ###\n","DATA_DIR = r'./sst2/'\n","SEED = 12345\n","torch.manual_seed(SEED)\n","numpy.random.seed(SEED)\n","project_name = 'sentiment_classification'\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"]},{"cell_type":"markdown","metadata":{"id":"Os9v_CBtUWbh"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7XZD41GsN_3F","executionInfo":{"status":"ok","timestamp":1745524000163,"user_tz":240,"elapsed":22,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n","test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n","train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=SEED)\n","train_df['data_split_type'] = \"train\"\n","val_df['data_split_type'] = \"val\"\n","test_df['data_split_type'] = \"test\"\n","df = pd.concat([train_df,val_df, test_df])\n","df.reset_index(drop=True, inplace=True)\n","df['sentiment'] = df['label']#.map({'positive': 1, 'negative': 0})\n","df['text_cleaned'] = df.sentence"]},{"cell_type":"markdown","metadata":{"id":"hqluLSxF2Vqz"},"source":["# PreProcess"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"u3oDWeaoN_3L","executionInfo":{"status":"ok","timestamp":1745524004642,"user_tz":240,"elapsed":4474,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["# # Only Customer Conversations | I will rerun this process with uncommenting this section when I am doing hyperparameter tunning\n","# df['text_cleaned'] = df['text_cleaned'].apply(\n","#     lambda x: \"\\n\".join([line.split(\":\", 1)[1].strip() for line in x.split('\\n') if line.startswith(\"Customer:\")]))\n","\n","# Lowering Case:\n","df['text_cleaned'] = df['text_cleaned'].str.lower()\n","\n","# Update the function to remove the entire specified pattern including variations in the agent's name\n","def remove_full_pattern(text):\n","    # Extended pattern to remove, including variations in agent names\n","    full_pattern = r\"Thank you for calling BrownBox Customer Support\\. My name is \\w+\\. How may I assist you today\\?\"\n","    # Remove the extended pattern\n","    text = re.sub(full_pattern, \"\", text, flags=re.IGNORECASE)\n","    return text.strip()\n","\n","# Apply the updated function to the 'conversation' column\n","df['text_cleaned'] = df['text_cleaned'].apply(remove_full_pattern)\n","\n","# Cleaning the \"Agent:\" and \"Customer:\"\n","df['text_cleaned'] = df['text_cleaned'].str.replace(r\"\\b(Agent:|Customer:)\\s*\", \"\", regex=True)\n","\n","# Remove email addresses and websites from the 'text_cleaned' column in one line\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda text: re.sub(r\"\\S+@\\S+|www\\.\\S+\\.com\", \"\", text))\n","\n","# Removing punctuation, numbers, extra spaces and replacing repetitions of punctuation\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'\\d+', '', x))\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join(x.split()))\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'(\\W)\\1+', r'\\1', x))\n","\n","# Convert Emojis to Words\n","def convert_emojis_to_words(text):\n","    converted_text = emoji.demojize(text)\n","    return converted_text\n","df['text_cleaned'] = df['text_cleaned'].apply(convert_emojis_to_words)\n","\n","# Removing special characters\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r\"[^\\w\\s]\", '', x))\n","\n","# Removing contractions\n","df['text_cleaned'] = df['text_cleaned'].apply(lambda x: contractions.fix(x))\n","\n","# Removing stop words:\n","stop_words_set = set(stopwords.words('english'))\n","no_stopwords = []\n","for sentence in df[\"text_cleaned\"]:\n","    # Use the new variable name here\n","    no_stopwords.append(' '.join(word for word in sentence.split() if word not in stop_words_set))\n","df[\"text_cleaned\"]=no_stopwords\n","\n","# Lemmitization\n","lemmatizer = WordNetLemmatizer()\n","def lemmatize_words(text):\n","    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n","\n","df[\"text_cleaned\"] = df[\"text_cleaned\"].apply(lambda text: lemmatize_words(text))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"4zLjbUgfN_3P","outputId":"787ce425-85c5-4556-9813-08bb37bd5e0c","executionInfo":{"status":"ok","timestamp":1745524004815,"user_tz":240,"elapsed":181,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Calculate the number of words in each conversation |  Before changing the preprocess part for hyperparmater tunning\n","df['word_count'] = df['text_cleaned'].str.split().str.len()\n","df = df[~((df['word_count'] < 8) & (df['data_split_type'] == 'train'))] #Removing no conversation in train dataset\n","# Plotting the histogram of conversation lengths\n","plt.figure(figsize=(10, 6))\n","plt.hist(df['word_count'], bins=50, color='blue', alpha=0.7)\n","plt.title('Distribution of Conversation Lengths (in Words)')\n","plt.xlabel('Number of Words')\n","plt.ylabel('Frequency')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"yIo7FIz8EdVJ","outputId":"8f0eb514-f45d-44a4-de56-db9419fa99eb","executionInfo":{"status":"ok","timestamp":1745524005010,"user_tz":240,"elapsed":193,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# Calculate the number of words in each conversation |  After changing the preprocess part for hyperparmater tunning\n","df['word_count'] = df['text_cleaned'].str.split().str.len()\n","df = df[~((df['word_count'] < 8) & (df['data_split_type'] == 'train'))] #Removing no conversation in train dataset\n","# Plotting the histogram of conversation lengths\n","plt.figure(figsize=(10, 6))\n","plt.hist(df['word_count'], bins=50, color='blue', alpha=0.7)\n","plt.title('Distribution of Conversation Lengths (in Words)')\n","plt.xlabel('Number of Words')\n","plt.ylabel('Frequency')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fhEU0wMn2kVQ"},"source":["# Model Design"]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, config, layer_num):\n","        super().__init__()\n","        self.layer_used = config.attention_layer\n","        if config.attention_layer == \"CausalSelfAttention\":\n","            self.attn_layer = CausalSelfAttention(config)\n","        elif config.attention_layer == \"MomentumAttention\":\n","            self.attn_layer = MomentumAttention(config, layer_num)\n","        elif config.attention_layer == \"AdaGradAttention\":\n","            self.attn_layer = AdaGradAttention(config, layer_num)\n","        elif config.attention_layer == \"RMSPropAttention\":\n","            self.attn_layer = RMSPropAttention(config, layer_num)\n","        elif config.attention_layer == \"AdamAttention\":\n","            self.attn_layer = AdamAttention(config, layer_num)\n","        elif config.attention_layer == \"MuonAttention\":\n","            self.attn_layer = MuonAttention(config, layer_num)\n","        else:\n","            raise ValueError(f\"config.attention_layer not valid.\\n \\\n","                             Valid values: CausalSelfAttention, MomentumAttention, AdaGradAttention, \\\n","                             RMSPropAttention, AdamAttention, MuonAttention\\n \\\n","                             Current: {config.attention_layer}\")\n","        print(f\"Attention used: {config.attention_layer}\")\n","\n","    def forward(self, x, m):\n","      if self.layer_used == \"AdamAttention\":\n","        return self.attn_layer(x, m, v)\n","      return self.attn_layer(x, m)\n","\n","class CausalSelfAttention(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","        # key, query, value projections for all heads, but in a batch\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        # output projection\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.dropout = config.dropout\n","        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n","        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n","        if not self.flash:\n","            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n","            # causal mask to ensure that attention is only applied to the left in the input sequence\n","            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n","                                        .view(1, 1, config.block_size, config.block_size))\n","\n","    def forward(self, x, m):\n","        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n","\n","        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n","        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        if self.flash:\n","            # efficient attention using Flash Attention CUDA kernels\n","            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n","        else:\n","            # manual implementation of attention\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","            att = F.softmax(att, dim=-1)\n","            att = self.attn_dropout(att)\n","            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y, None\n","\n","# Momentum-Based Attention\n","class MomentumAttention(nn.Module):\n","    \"\"\"\n","    Momentum Attention\n","    Introduced in https://arxiv.org/pdf/2212.10559v2\n","    \"\"\"\n","\n","    def __init__(self, config, layer_num):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.dropout = config.dropout\n","\n","        # causal mask to ensure that attention is only applied to the left in the input sequence\n","        self.register_buffer(\"bias\",\n","                             torch.tril(torch.ones(config.block_size, config.block_size))\n","                                  .view(1, 1, config.block_size, config.block_size))\n","\n","        # momentum\n","        t = layer_num\n","        eta = torch.tensor([config.momentum_eta]).to(\"cuda\")\n","        self.momentum_scale = torch.pow(eta, t)\n","\n","    def forward(self, x, m):\n","        \"\"\"\n","        Forward implementation of MomentumAttention\n","        params:\n","            x: input (B, T, C)\n","                B - batch size\n","                T - sequence length\n","                C - embedding dimensionality (n_embd)\n","            m: momentum term at t-1\n","            t: t-th layer\n","        returns:\n","            y: momentum attention\n","            m: momentum term at t\n","        \"\"\"\n","        B, T, C = x.size()\n","        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.resid_dropout(self.c_proj(y))\n","\n","        # momentum\n","        y = y + m\n","        m = m + self.momentum_scale * y\n","        return y, m\n","\n","class AdaGradAttention(nn.Module):\n","    \"\"\"\n","    AdaGrad Attention\n","    Introduced in 10-707 Final Project\n","    \"\"\"\n","    #TODO: Implement AdaGrad Attention\n","\n","    def __init__(self, config, layer_num):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.dropout = config.dropout\n","\n","        # causal mask to ensure that attention is only applied to the left in the input sequence\n","        self.register_buffer(\"bias\",\n","                             torch.tril(torch.ones(config.block_size, config.block_size))\n","                                  .view(1, 1, config.block_size, config.block_size))\n","\n","        # momentum\n","        t = layer_num\n","        eta = torch.tensor([config.momentum_eta]).to(\"cuda\")\n","        self.momentum_scale = torch.pow(eta, t)\n","        self.eps = 1E-5\n","\n","    def forward(self, x, m):\n","        \"\"\"\n","        Forward implementation of MomentumAttention\n","        params:\n","            x: input (B, T, C)\n","                B - batch size\n","                T - sequence length\n","                C - embedding dimensionality (n_embd)\n","            m: momentum term at t-1\n","            t: t-th layer\n","        returns:\n","            y: momentum attention\n","            m: momentum term at t\n","        \"\"\"\n","        B, T, C = x.size()\n","        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.resid_dropout(self.c_proj(y))\n","\n","        # AdaGrad momentum\n","        y = y + m\n","        X = y * y\n","        adagrad_update = torch.pow(X+self.eps, -0.5) * y\n","        m = m + self.momentum_scale * adagrad_update\n","        return y, m\n","\n","class RMSPropAttention(nn.Module):\n","    \"\"\"\n","    RMSProp Attention\n","    Introduced in 10-707 Final Project\n","    \"\"\"\n","    def __init__(self, config, layer_num):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.dropout = config.dropout\n","\n","        # causal mask to ensure that attention is only applied to the left in the input sequence\n","        self.register_buffer(\"bias\",\n","                             torch.tril(torch.ones(config.block_size, config.block_size))\n","                                  .view(1, 1, config.block_size, config.block_size))\n","\n","        # momentum\n","        self.rho = 0.1\n","        self.eps = 1e-8\n","        self.layer_num = layer_num\n","        self.eta = config.momentum_eta\n","        self.momentum_scale = torch.pow(torch.tensor([self.eta]).to(\"cuda\"), self.layer_num)\n","\n","        print(f\"self.rho = {self.rho}\")\n","\n","\n","    def forward(self, x, m):\n","        \"\"\"\n","        Forward implementation of RMSPropAttention\n","        params:\n","            x: input (B, T, C)\n","                B - batch size\n","                T - sequence length\n","                C - embedding dimensionality (n_embd)\n","            m: momentum term at t-1\n","            t: t-th layer\n","        returns:\n","            y: momentum attention\n","            m: momentum term at t\n","        \"\"\"\n","        B, T, C = x.size()\n","        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n","        att = F.softmax(att, dim=-1)\n","        att = self.attn_dropout(att)\n","        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.resid_dropout(self.c_proj(y))\n","\n","        # RMSProp momentum\n","        if m is None:\n","            m = torch.zeros_like(y)\n","\n","        y = y + m\n","        X = y * y\n","        rmsprop_update = torch.pow(X+self.eps, -0.5) * y\n","        m = self.rho * m + (1 - self.rho) * rmsprop_update\n","        # print(m.shape)\n","\n","        # y = y + m\n","        # X = y * y\n","        # adagrad_update = torch.pow(X+self.eps, -0.5) * y\n","        # m = m + self.momentum_scale * adagrad_update\n","        return y, m"],"metadata":{"id":"iowIPAqqO2bB","executionInfo":{"status":"ok","timestamp":1745524071306,"user_tz":240,"elapsed":50,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"tXzlAe8EdDyH","executionInfo":{"status":"ok","timestamp":1745524005065,"user_tz":240,"elapsed":19,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["class FullSelfAttention(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        assert config.n_embd % config.n_head == 0\n","        # key, query, value projections for all heads, but in a batch\n","        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n","        # output projection\n","        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n","        # regularization\n","        self.attn_dropout = nn.Dropout(config.dropout)\n","        self.resid_dropout = nn.Dropout(config.dropout)\n","        self.n_head = config.n_head\n","        self.n_embd = config.n_embd\n","        self.dropout = config.dropout\n","        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n","        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n","\n","    def forward(self, x):\n","        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n","\n","        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n","        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n","        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n","\n","        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n","        if self.flash:\n","            # efficient attention using Flash Attention CUDA kernels\n","            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=False)\n","        else:\n","            # manual implementation of attention\n","            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n","            att = F.softmax(att, dim=-1)\n","            att = self.attn_dropout(att)\n","            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n","        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n","\n","        # output projection\n","        y = self.resid_dropout(self.c_proj(y))\n","        return y\n","class MLP(nn.Module):\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n","        self.gelu    = nn.GELU()\n","        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, x):\n","        x = self.c_fc(x)\n","        x = self.gelu(x)\n","        x = self.c_proj(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class Block(nn.Module):\n","\n","    def __init__(self, config, layer_num):\n","        super().__init__()\n","        self.ln_1 = LayerNorm(config.n_embd, bias=config.bias)\n","        self.attn = Attention(config, layer_num)\n","        self.ln_2 = LayerNorm(config.n_embd, bias=config.bias)\n","        self.mlp = MLP(config)\n","\n","    def forward(self, x, m):\n","        x = self.ln_1(x)\n","        x_attn, m_attn = self.attn(x, m)\n","        x = x + x_attn\n","        x = self.ln_2(x)\n","        x = x + self.mlp(x)\n","        return x, m_attn\n","\n","class BumbleBee(GPT):\n","    def __init__(self, config, num_classes=3): # The output of the sentimenet analysis will be 0, 1, 2.\n","        super().__init__(config)\n","\n","        self.config = config\n","\n","        self.transformer = nn.ModuleDict(dict(\n","            wte = nn.Embedding(config.vocab_size, config.n_embd),\n","            wpe = nn.Embedding(config.block_size, config.n_embd),\n","            drop = nn.Dropout(config.dropout),\n","            h = nn.ModuleList([Block(config, i) for i in range(config.n_layer)]),\n","            ln_f = LayerNorm(config.n_embd, bias=config.bias),\n","        ))\n","        # Override the lm_head with a new linear layer for sentiment classification\n","        self.lm_head = torch.nn.Linear(config.n_embd, num_classes, bias=False)\n","\n","    def forward(self, idx):\n","        device = idx.device\n","        b, t = idx.size()\n","        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n","        pos = torch.arange(0, t, dtype=torch.long, device=device)  # shape (t)\n","\n","        # Forward the GPT model\n","        tok_emb = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)\n","        pos_emb = self.transformer.wpe(pos)  # position embeddings of shape (t, n_embd)\n","        x = self.transformer.drop(tok_emb + pos_emb)\n","        self.m = torch.zeros((self.config.n_embd)).to(\"cuda\")\n","        for block in self.transformer.h:\n","            x, self.m = block(x, self.m)\n","        x = self.transformer.ln_f(x)\n","\n","        # Aggregate sequence representations (average over the sequence)\n","        x = torch.mean(x, dim=1)\n","\n","        # Pass through the modified linear layer to get class logits\n","        logits = self.lm_head(x)\n","\n","        return logits\n","\n","    @classmethod\n","    def from_pretrained(cls, model_type, override_args=None):\n","        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n","        override_args = override_args or {} # default to empty dict\n","        # only dropout can be overridden see more notes below\n","        assert all(k == 'dropout' for k in override_args)\n","        from transformers import GPT2LMHeadModel\n","        print(\"loading weights from pretrained gpt: %s\" % model_type)\n","\n","        # n_layer, n_head and n_embd are determined from model_type\n","        config_args = {\n","            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n","            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n","            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n","            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n","        }[model_type]\n","        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n","        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n","        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n","        config_args['bias'] = True # always True for GPT model checkpoints\n","\n","\n","\n","        # we can override the dropout rate, if desired\n","        if 'dropout' in override_args:\n","            print(f\"overriding dropout rate to {override_args['dropout']}\")\n","            config_args['dropout'] = override_args['dropout']\n","        # create a from-scratch initialized minGPT model\n","        config = GPTConfig(**config_args)\n","        model = BumbleBee(config)\n","        sd = model.state_dict()\n","        sd_keys = sd.keys()\n","        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n","\n","        # init a huggingface/transformers model\n","        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n","        sd_hf = model_hf.state_dict()\n","\n","        # copy while ensuring all of the parameters are aligned and match in names and shapes\n","        sd_keys_hf = sd_hf.keys()\n","        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n","        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n","        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n","        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n","        # this means that we have to transpose these weights when we import them\n","        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n","        for k in sd_keys_hf:\n","            if any(k.endswith(w) for w in transposed):\n","                # special treatment for the Conv1D weights we need to transpose\n","                assert sd_hf[k].shape[::-1] == sd[k].shape\n","                with torch.no_grad():\n","                    sd[k].copy_(sd_hf[k].t())\n","            else:\n","                # vanilla copy over the other parameters\n","                if k != 'lm_head.weight': # Except Last layer\n","                    assert sd_hf[k].shape == sd[k].shape\n","                    with torch.no_grad():\n","                        sd[k].copy_(sd_hf[k])\n","\n","        return model\n","\n","class CustomerSentimentDataset(Dataset):\n","    def __init__(self, df, tokenizer, max_length=256, text_column='text_cleaned', sentiment_column='sentiment',):\n","        self.data = df\n","        self.texts = self.data[text_column].values\n","        self.labels = self.data[sentiment_column].values\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","\n","        # Use the tokenizer's method to encode the text\n","        input_ids = self.tokenizer.encode(text)\n","\n","        # Ensure the sequence is at most max_length\n","        input_ids = input_ids[:self.max_length]\n","\n","        # Padding if necessary to ensure all sequences are of the same length\n","        padding_length = self.max_length - len(input_ids)\n","        if padding_length > 0:\n","            # Append zeros at the end for padding\n","            input_ids = input_ids + [0] * padding_length\n","\n","        # Ensure it returns a torch tensor\n","        input_ids = torch.tensor(input_ids, dtype=torch.long)\n","\n","        return input_ids, torch.tensor(label, dtype=torch.long)"]},{"cell_type":"markdown","metadata":{"id":"9kRU4hmudJ5c"},"source":["# Training & Evaluation Metric Definations"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"b1TcJR-NN_3Q","executionInfo":{"status":"ok","timestamp":1745524609588,"user_tz":240,"elapsed":11,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["def train_and_evaluate():\n","    current_time = datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n","    wandb.init(project=\"customser_service_sentiment_analysis\", name=f\"run_{current_time}\")\n","    config = wandb.config\n","\n","    if config.init_from == 'scratch':\n","        model_config = GPTConfig(vocab_size=config.vocab_size,\n","                                 block_size=config.block_size,\n","                                 n_layer=config.n_layer,\n","                                 n_head=config.n_head,\n","                                 n_embd=config.n_embd,\n","                                 dropout=config.dropout,\n","                                 attention_layer=\"RMSPropAttention\")\n","        model = BumbleBee(model_config).to(device)\n","    elif str(config.init_from).startswith('gpt'):\n","        model_config = dict(dropout=config.dropout)\n","        model = BumbleBee.from_pretrained(model_type=config.init_from, override_args=model_config).to(device)\n","    else:\n","        print('please select correct model!')\n","\n","    optimizer = model.configure_optimizers(weight_decay=config.weight_decay,\n","                                           learning_rate=config.learning_rate,\n","                                           betas=(config.beta1, config.beta2),\n","                                           device_type=device)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n","\n","    best_f1_macro = 0\n","    best_val_loss = float('inf')\n","    best_model_path = \"\"\n","\n","    for epoch in range(config.epochs):\n","        model.train()\n","        # Initialize lists to store batch metrics\n","        train_losses, train_f1s, train_precs, train_recs, train_accs = [], [], [], [], []\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            logits = model(inputs)\n","            loss = F.cross_entropy(logits, labels)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n","            optimizer.step()\n","\n","            # Calculate and store batch metrics\n","            train_losses.append(loss.item())\n","            predictions = logits.argmax(dim=1).cpu().numpy()\n","            labels_np = labels.cpu().numpy()\n","            train_f1s.append(f1_score(labels_np, predictions, average='macro'))\n","            train_precs.append(precision_score(labels_np, predictions, average='macro', zero_division=0))\n","            train_recs.append(recall_score(labels_np, predictions, average='macro', zero_division=0))\n","            train_accs.append(accuracy_score(labels_np, predictions))\n","\n","        # Calculate average metrics over all batches\n","        avg_train_loss = np.mean(train_losses)\n","        avg_train_f1 = np.mean(train_f1s)\n","        avg_train_prec = np.mean(train_precs)\n","        avg_train_rec = np.mean(train_recs)\n","        avg_train_acc = np.mean(train_accs)\n","\n","        model.eval()\n","        val_loss, val_f1, val_prec, val_rec, val_acc, val_conf_matrix = evaluate(model, val_loader)\n","        print(f\"\\nEpoch {epoch+1}, Train Loss: {avg_train_loss:.2f}, Train F1 Macro: {avg_train_f1:.2f}, Train Precision Macro: {avg_train_prec:.2f}, Train Recall Macro: {avg_train_rec:.2f}, Train Accuracy: {avg_train_acc:.2f}\")\n","        print(f\"Epoch {epoch+1}, Val Loss: {val_loss:.2f}, Val F1 Macro: {val_f1:.2f}, Val Precision Macro: {val_prec:.2f}, Val Recall Macro: {val_rec:.2f}, Val Accuracy: {val_acc:.2f}\")\n","\n","        # Saving the best F1 macro result model\n","        if val_f1 > best_f1_macro:\n","            best_f1_macro = val_f1\n","            best_model_path = f\"{DATA_DIR}/best_model_{current_time}.pt\"\n","            checkpoint = {\n","                'model': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'model_args': model_config,\n","                'epoch_num': epoch+1,\n","                'best_val_loss': best_val_loss,\n","                'config': {k: v for k, v in dict(wandb.config).items()},\n","            }\n","            torch.save(checkpoint, best_model_path)\n","\n","        # Log both training and validation metrics to W&B\n","        wandb.log({\n","            \"epoch\": epoch + 1,\n","            \"train_loss\": avg_train_loss, \"train_f1_macro\": avg_train_f1, \"train_precision_macro\": avg_train_prec, \"train_recall_macro\": avg_train_rec, \"train_accuracy\": avg_train_acc,\n","            \"val_loss\": val_loss, \"val_f1_macro\": val_f1, \"val_precision_macro\": val_prec, \"val_recall_macro\": val_rec, \"val_accuracy\": val_acc\n","        })\n","\n","    # Load the best model and evaluate on test data\n","    model.load_state_dict(torch.load(best_model_path)['model'])\n","    test_loss, test_f1, test_prec, test_rec, test_acc, test_conf_matrix = evaluate(model, test_loader)\n","    print(f\"\\nBest model epoch {checkpoint['epoch_num']} and test results, Test Loss: {test_loss:.2f}, Test F1 Macro: {test_f1:.2f}, Test Precision Macro: {test_prec:.2f}, Test Recall Macro: {test_rec:.2f}, Test Accuracy: {test_acc:.2f}\")\n","\n","\n","    fig = plot_confusion_matrix(test_conf_matrix, class_names=['Positive', 'Neutral', 'Negative'])\n","    wandb.log({\"test_confusion_matrix\": wandb.Image(fig)})\n","\n","    # Log test results to W&B\n","    wandb.log(\n","              {\"test_loss\": test_loss,\n","               \"test_f1_macro\": test_f1,\n","               \"test_precision_macro\": test_prec,\n","               \"test_recall_macro\": test_rec}\n","              )\n","    wandb.finish()\n","\n","\n","def evaluate(model, loader):\n","    total_loss = 0\n","    all_preds, all_labels = [], []\n","    with torch.no_grad():\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            logits = model(inputs)\n","            loss = F.cross_entropy(logits, labels)\n","            total_loss += loss.item()\n","            preds = torch.argmax(logits, dim=1)\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    avg_loss = total_loss / len(loader)\n","    f1_macro = f1_score(all_labels, all_preds, average='macro')\n","    precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n","    recall_macro = recall_score(all_labels, all_preds, average='macro')\n","    conf_matrix = confusion_matrix(all_labels, all_preds)\n","    accuracy = accuracy_score(all_labels, all_preds)\n","    return avg_loss, f1_macro, precision_macro, recall_macro, accuracy, conf_matrix\n","\n","def plot_confusion_matrix(cm, class_names):\n","    figure = plt.figure(figsize=(8, 8))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=plt.cm.Blues, cbar=False, xticklabels=class_names, yticklabels=class_names)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.close()\n","    return figure\n"]},{"cell_type":"markdown","metadata":{"id":"ihwX5SNofjHY"},"source":["# From Scratch"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"SLbyIr1BgpVb","executionInfo":{"status":"ok","timestamp":1745524612685,"user_tz":240,"elapsed":4,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["# Assigning tokinezer\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","# Load the dataset\n","train_dataset = CustomerSentimentDataset(df[df.data_split_type == 'train'], max_length=1024, tokenizer=tokenizer)\n","test_dataset = CustomerSentimentDataset(df[df.data_split_type == 'test'], max_length=1024, tokenizer=tokenizer)\n","val_dataset = CustomerSentimentDataset(df[df.data_split_type == 'val'], max_length=1024, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"i3WeEUkHN_3T","outputId":"ed22d43c-c0aa-4b03-ba65-a54521a49d0d","executionInfo":{"status":"ok","timestamp":1745525963314,"user_tz":240,"elapsed":1349337,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: irayl0qt\n","Sweep URL: https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/irayl0qt\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zib131y6 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tblock_size: 1024\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_from: scratch\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tn_embd: 384\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tn_head: 6\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tn_layer: 6\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tvocab_size: 50304\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Ignoring project 'customser_service_sentiment_analysis' when running a sweep."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis/wandb/run-20250424_195655-zib131y6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/zib131y6' target=\"_blank\">run_24-04-2025_19-56-55</a></strong> to <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/irayl0qt' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/irayl0qt</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/irayl0qt' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/irayl0qt</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/zib131y6' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/zib131y6</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["number of parameters: 29.96M\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","self.rho = 0.1\n","Attention used: RMSPropAttention\n","num decayed parameter tensors: 27, with 30,327,936 parameters\n","num non-decayed parameter tensors: 50, with 30,720 parameters\n","using fused AdamW: True\n","\n","Epoch 1, Train Loss: 0.73, Train F1 Macro: 0.34, Train Precision Macro: 0.29, Train Recall Macro: 0.50, Train Accuracy: 0.50\n","Epoch 1, Val Loss: 0.70, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 2, Train Loss: 0.70, Train F1 Macro: 0.35, Train Precision Macro: 0.28, Train Recall Macro: 0.50, Train Accuracy: 0.53\n","Epoch 2, Val Loss: 0.69, Val F1 Macro: 0.51, Val Precision Macro: 0.52, Val Recall Macro: 0.52, Val Accuracy: 0.51\n","\n","Epoch 3, Train Loss: 0.70, Train F1 Macro: 0.35, Train Precision Macro: 0.31, Train Recall Macro: 0.50, Train Accuracy: 0.51\n","Epoch 3, Val Loss: 0.69, Val F1 Macro: 0.49, Val Precision Macro: 0.55, Val Recall Macro: 0.53, Val Accuracy: 0.55\n","\n","Epoch 4, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.33, Train Recall Macro: 0.51, Train Accuracy: 0.51\n","Epoch 4, Val Loss: 0.69, Val F1 Macro: 0.49, Val Precision Macro: 0.55, Val Recall Macro: 0.53, Val Accuracy: 0.55\n","\n","Epoch 5, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.34, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 5, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 6, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.33, Train Recall Macro: 0.51, Train Accuracy: 0.51\n","Epoch 6, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 7, Train Loss: 0.69, Train F1 Macro: 0.38, Train Precision Macro: 0.36, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 7, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 8, Train Loss: 0.69, Train F1 Macro: 0.42, Train Precision Macro: 0.43, Train Recall Macro: 0.53, Train Accuracy: 0.53\n","Epoch 8, Val Loss: 0.70, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 9, Train Loss: 0.69, Train F1 Macro: 0.40, Train Precision Macro: 0.40, Train Recall Macro: 0.52, Train Accuracy: 0.52\n","Epoch 9, Val Loss: 0.70, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 10, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.33, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 10, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 11, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.33, Train Recall Macro: 0.50, Train Accuracy: 0.52\n","Epoch 11, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.77, Val Recall Macro: 0.50, Val Accuracy: 0.54\n","\n","Epoch 12, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.34, Train Recall Macro: 0.51, Train Accuracy: 0.54\n","Epoch 12, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.52, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 13, Train Loss: 0.69, Train F1 Macro: 0.41, Train Precision Macro: 0.41, Train Recall Macro: 0.52, Train Accuracy: 0.54\n","Epoch 13, Val Loss: 0.69, Val F1 Macro: 0.47, Val Precision Macro: 0.55, Val Recall Macro: 0.53, Val Accuracy: 0.55\n","\n","Epoch 14, Train Loss: 0.69, Train F1 Macro: 0.42, Train Precision Macro: 0.43, Train Recall Macro: 0.52, Train Accuracy: 0.53\n","Epoch 14, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.77, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 15, Train Loss: 0.70, Train F1 Macro: 0.37, Train Precision Macro: 0.34, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 15, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 16, Train Loss: 0.70, Train F1 Macro: 0.35, Train Precision Macro: 0.29, Train Recall Macro: 0.50, Train Accuracy: 0.52\n","Epoch 16, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 17, Train Loss: 0.69, Train F1 Macro: 0.37, Train Precision Macro: 0.33, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 17, Val Loss: 0.72, Val F1 Macro: 0.32, Val Precision Macro: 0.23, Val Recall Macro: 0.50, Val Accuracy: 0.47\n","\n","Epoch 18, Train Loss: 0.69, Train F1 Macro: 0.37, Train Precision Macro: 0.35, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 18, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.77, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 19, Train Loss: 0.70, Train F1 Macro: 0.36, Train Precision Macro: 0.30, Train Recall Macro: 0.50, Train Accuracy: 0.52\n","Epoch 19, Val Loss: 0.70, Val F1 Macro: 0.32, Val Precision Macro: 0.23, Val Recall Macro: 0.50, Val Accuracy: 0.47\n","\n","Epoch 20, Train Loss: 0.69, Train F1 Macro: 0.36, Train Precision Macro: 0.32, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 20, Val Loss: 0.70, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 21, Train Loss: 0.70, Train F1 Macro: 0.36, Train Precision Macro: 0.30, Train Recall Macro: 0.51, Train Accuracy: 0.52\n","Epoch 21, Val Loss: 0.69, Val F1 Macro: 0.51, Val Precision Macro: 0.54, Val Recall Macro: 0.54, Val Accuracy: 0.52\n","\n","Epoch 22, Train Loss: 0.69, Train F1 Macro: 0.35, Train Precision Macro: 0.30, Train Recall Macro: 0.50, Train Accuracy: 0.52\n","Epoch 22, Val Loss: 0.69, Val F1 Macro: 0.35, Val Precision Macro: 0.27, Val Recall Macro: 0.50, Val Accuracy: 0.53\n","\n","Epoch 23, Train Loss: 0.69, Train F1 Macro: 0.42, Train Precision Macro: 0.43, Train Recall Macro: 0.53, Train Accuracy: 0.54\n","Epoch 23, Val Loss: 0.71, Val F1 Macro: 0.32, Val Precision Macro: 0.23, Val Recall Macro: 0.50, Val Accuracy: 0.47\n","\n","Epoch 24, Train Loss: 0.69, Train F1 Macro: 0.39, Train Precision Macro: 0.39, Train Recall Macro: 0.52, Train Accuracy: 0.52\n","Epoch 24, Val Loss: 0.69, Val F1 Macro: 0.56, Val Precision Macro: 0.57, Val Recall Macro: 0.57, Val Accuracy: 0.56\n","\n","Epoch 25, Train Loss: 0.69, Train F1 Macro: 0.42, Train Precision Macro: 0.42, Train Recall Macro: 0.52, Train Accuracy: 0.53\n","Epoch 25, Val Loss: 0.70, Val F1 Macro: 0.32, Val Precision Macro: 0.23, Val Recall Macro: 0.50, Val Accuracy: 0.47\n","\n","Epoch 26, Train Loss: 0.69, Train F1 Macro: 0.42, Train Precision Macro: 0.46, Train Recall Macro: 0.52, Train Accuracy: 0.53\n","Epoch 26, Val Loss: 0.69, Val F1 Macro: 0.38, Val Precision Macro: 0.62, Val Recall Macro: 0.51, Val Accuracy: 0.54\n","\n","Epoch 27, Train Loss: 0.68, Train F1 Macro: 0.48, Train Precision Macro: 0.54, Train Recall Macro: 0.55, Train Accuracy: 0.56\n","Epoch 27, Val Loss: 0.70, Val F1 Macro: 0.42, Val Precision Macro: 0.57, Val Recall Macro: 0.52, Val Accuracy: 0.50\n","\n","Epoch 28, Train Loss: 0.69, Train F1 Macro: 0.45, Train Precision Macro: 0.51, Train Recall Macro: 0.53, Train Accuracy: 0.54\n","Epoch 28, Val Loss: 0.69, Val F1 Macro: 0.39, Val Precision Macro: 0.58, Val Recall Macro: 0.51, Val Accuracy: 0.54\n","\n","Epoch 29, Train Loss: 0.69, Train F1 Macro: 0.47, Train Precision Macro: 0.54, Train Recall Macro: 0.54, Train Accuracy: 0.55\n","Epoch 29, Val Loss: 0.70, Val F1 Macro: 0.40, Val Precision Macro: 0.56, Val Recall Macro: 0.51, Val Accuracy: 0.54\n","\n","Epoch 30, Train Loss: 0.69, Train F1 Macro: 0.48, Train Precision Macro: 0.57, Train Recall Macro: 0.55, Train Accuracy: 0.56\n","Epoch 30, Val Loss: 0.69, Val F1 Macro: 0.41, Val Precision Macro: 0.57, Val Recall Macro: 0.51, Val Accuracy: 0.54\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▅▂▂▃▃▃▅▃▃▃▅▅▄▃▃▃▃▄▃▃▃▆▄▅▄█▅▆█</td></tr><tr><td>train_f1_macro</td><td>▁▁▂▂▂▂▃▅▄▂▂▃▄▅▂▁▂▂▂▂▂▂▅▃▅▅█▆▇█</td></tr><tr><td>train_loss</td><td>█▄▃▃▃▃▃▃▃▃▃▃▂▂▄▃▃▂▃▂▃▃▂▃▂▂▁▂▂▁</td></tr><tr><td>train_precision_macro</td><td>▁▁▂▂▂▂▃▅▄▂▂▂▄▅▂▁▂▃▁▂▁▁▅▄▄▅▇▇▇█</td></tr><tr><td>train_recall_macro</td><td>▁▁▁▂▂▃▃▅▃▂▂▂▄▄▃▂▂▂▁▂▂▁▆▃▅▄█▅▇█</td></tr><tr><td>val_accuracy</td><td>▆▄▇▇▆▆▆▆▆▆▆▆▇▆▆▆▁▆▁▆▅▆▁█▁▆▃▆▆▇</td></tr><tr><td>val_f1_macro</td><td>▂▆▆▆▂▂▂▂▂▂▂▂▅▂▂▂▁▂▁▂▆▂▁█▁▃▄▃▃▄</td></tr><tr><td>val_loss</td><td>▄▃▂▂▂▂▃▃▃▂▂▂▁▂▂▂█▂▆▄▂▂▆▂▅▂▅▁▃▁</td></tr><tr><td>val_precision_macro</td><td>▁▅▅▅▁▁▁▁▁▁█▅▅█▁▁▁█▁▁▅▁▁▅▁▆▅▅▅▅</td></tr><tr><td>val_recall_macro</td><td>▁▃▄▄▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▅▁▁█▁▂▄▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>train_accuracy</td><td>0.55995</td></tr><tr><td>train_f1_macro</td><td>0.47882</td></tr><tr><td>train_loss</td><td>0.68723</td></tr><tr><td>train_precision_macro</td><td>0.56871</td></tr><tr><td>train_recall_macro</td><td>0.54743</td></tr><tr><td>val_accuracy</td><td>0.5448</td></tr><tr><td>val_f1_macro</td><td>0.41186</td></tr><tr><td>val_loss</td><td>0.68504</td></tr><tr><td>val_precision_macro</td><td>0.56721</td></tr><tr><td>val_recall_macro</td><td>0.51488</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">run_24-04-2025_19-56-55</strong> at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/zib131y6' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/zib131y6</a><br> View project at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250424_195655-zib131y6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run zib131y6 errored:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-21-1d3516eb3897>\", line 90, in train_and_evaluate\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model.load_state_dict(torch.load(best_model_path)['model'])\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/serialization.py\", line 1470, in load\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise pickle.UnpicklingError(_get_wo_message(str(e))) from None\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m _pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \tWeightsUnpickler error: Unsupported global: GLOBAL model.GPTConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([GPTConfig])` or the `torch.serialization.safe_globals([GPTConfig])` context manager to allowlist this global if you trust this class/function.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"]}],"source":["sweep_config = {\n","    'method': 'grid',\n","    'parameters': {\n","        'epochs': {\n","            'value': 30\n","        },\n","        'batch_size': {\n","            'values': [32]\n","        },\n","        'vocab_size': {\n","            'values': [50304]\n","        },\n","        'block_size': {\n","            'values': [1024]\n","        },\n","        'n_layer': {\n","            'values': [6]\n","        },\n","        'n_head': {\n","            'values': [6]\n","        },\n","        'n_embd': {\n","            'values': [384]\n","        },\n","        'dropout': {\n","           'values': [0.3]\n","        },\n","        'learning_rate': {\n","            'values': [0.0001]\n","        },\n","        'weight_decay': {\n","            'values': [0.01]\n","        },\n","        'max_grad_norm': {\n","            'values': [1.0]\n","        },\n","        'beta1': {\n","            'values': [0.9]\n","        },\n","        'beta2': {\n","            'values': [0.999]\n","        },\n","        'init_from': {\n","            'value': 'scratch'\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=project_name)\n","\n","wandb.agent(sweep_id=sweep_id, function=train_and_evaluate)"]},{"cell_type":"markdown","metadata":{"id":"oLKR_qNAQrcL"},"source":["# Fine Tunning"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"IXkbfADv5939","executionInfo":{"status":"ok","timestamp":1745524019609,"user_tz":240,"elapsed":13,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["# Assigning tokinezer\n","tokenizer = tiktoken.get_encoding(\"gpt2\")\n","\n","# Load the dataset\n","train_dataset = CustomerSentimentDataset(df[df.data_split_type == 'train'], max_length=1024, tokenizer=tokenizer)\n","test_dataset = CustomerSentimentDataset(df[df.data_split_type == 'test'], max_length=1024, tokenizer=tokenizer)\n","val_dataset = CustomerSentimentDataset(df[df.data_split_type == 'val'], max_length=1024, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Ed5d79vAQsXv","outputId":"b1b6e6c5-a65f-4882-9352-770fb37055e6","executionInfo":{"status":"ok","timestamp":1745524040735,"user_tz":240,"elapsed":21124,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: rk9ib0ef\n","Sweep URL: https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/rk9ib0ef\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mkc567i7 with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_from: gpt2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Ignoring project 'customser_service_sentiment_analysis' when running a sweep."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis/wandb/run-20250424_194700-mkc567i7</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mkc567i7' target=\"_blank\">run_24-04-2025_19-47-00</a></strong> to <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/rk9ib0ef' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/rk9ib0ef</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/rk9ib0ef' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/rk9ib0ef</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mkc567i7' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mkc567i7</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.3\n","number of parameters: 123.65M\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">run_24-04-2025_19-47-00</strong> at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mkc567i7' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mkc567i7</a><br> View project at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250424_194700-mkc567i7/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run mkc567i7 errored:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-5f50d447e20c>\", line 17, in train_and_evaluate\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = BumbleBee.from_pretrained(model_type=config.init_from, override_args=model_config).to(device)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-9-adc9f781450b>\", line 164, in from_pretrained\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     assert sd_hf[k].shape[::-1] == sd[k].shape\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ~~^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'transformer.h.0.attn.c_attn.weight'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"]}],"source":["sweep_config = {\n","    'method': 'grid',\n","    'parameters': {\n","        'epochs': {\n","            'value': 30\n","        },\n","        'batch_size': {\n","            'values': [32]\n","        },\n","        'dropout': {\n","           'values': [0.3]\n","        },\n","        'learning_rate': {\n","            'values': [0.001]\n","        },\n","        'weight_decay': {\n","            'values': [0.1]\n","        },\n","        'max_grad_norm': {\n","            'values': [1.0]\n","        },\n","        'beta1': {\n","            'values': [0.9]\n","        },\n","        'beta2': {\n","            'values': [0.999]\n","        },\n","        'init_from': {\n","            'value': 'gpt2'\n","        },\n","    }\n","}\n","\n","\n","sweep_id = wandb.sweep(sweep_config, project=project_name)\n","\n","wandb.agent(sweep_id=sweep_id, function=train_and_evaluate)"]},{"cell_type":"markdown","metadata":{"id":"UWZfDiBjoS0E"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"nGrL3XsT5QoH","executionInfo":{"status":"ok","timestamp":1745524043598,"user_tz":240,"elapsed":2857,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":["\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","max_length = 128\n","\n","# Tokenize the data\n","X_train_encoded = tokenizer.batch_encode_plus(df['text_cleaned'][df['data_split_type'] == 'train'].tolist(),\n","                                              padding=True,\n","                                              truncation=True,\n","                                              max_length = max_length,\n","                                              return_tensors='pt')['input_ids']\n","\n","X_val_encoded = tokenizer.batch_encode_plus(df['text_cleaned'][df['data_split_type'] == 'val'].tolist(),\n","                                              padding=True,\n","                                              truncation=True,\n","                                              max_length = max_length,\n","                                              return_tensors='pt')['input_ids']\n","\n","X_test_encoded = tokenizer.batch_encode_plus(df['text_cleaned'][df['data_split_type'] == 'test'].tolist(),\n","                                              padding=True,\n","                                              truncation=True,\n","                                              max_length = max_length,\n","                                              return_tensors='pt')['input_ids']\n","\n","\n","class BERTDataset(Dataset):\n","  def __init__(self, encoded_inputs, labels):\n","      \"\"\"\n","      Args:\n","          encoded_inputs (torch.Tensor): Pre-encoded input IDs for training/validation/testing.\n","          labels (list of int): Corresponding labels for the input data.\n","      \"\"\"\n","      self.encoded_inputs = encoded_inputs\n","      self.labels = torch.tensor(labels, dtype=torch.long)\n","\n","  def __len__(self):\n","      return len(self.labels)\n","\n","  def __getitem__(self, idx):\n","      \"\"\"\n","      Returns:\n","          input_ids: the pre-encoded tensor of input IDs (as a detached copy)\n","          label: the label for the input IDs at this index\n","      \"\"\"\n","      input_ids = self.encoded_inputs[idx].clone().detach()\n","      label = self.labels[idx]\n","      return input_ids, label\n","\n","train_labels = df[df['data_split_type'] == 'train']['sentiment'].tolist()\n","val_labels = df[df['data_split_type'] == 'val']['sentiment'].tolist()\n","test_labels = df[df['data_split_type'] == 'test']['sentiment'].tolist()\n","\n","train_dataset = BERTDataset(X_train_encoded, train_labels)\n","val_dataset = BERTDataset(X_val_encoded, val_labels)\n","test_dataset = BERTDataset(X_test_encoded, test_labels)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"cXDBthPRlmxr","outputId":"c6e36c4e-eb33-44e3-a2df-5baa13964a5c","executionInfo":{"status":"ok","timestamp":1745524070746,"user_tz":240,"elapsed":27147,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Create sweep with ID: m3sq2xrg\n","Sweep URL: https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qqa3igmx with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_from: gpt2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Ignoring project 'customser_service_sentiment_analysis' when running a sweep."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis/wandb/run-20250424_194725-qqa3igmx</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/qqa3igmx' target=\"_blank\">run_24-04-2025_19-47-24</a></strong> to <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/qqa3igmx' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/qqa3igmx</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.3\n","number of parameters: 123.65M\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">run_24-04-2025_19-47-24</strong> at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/qqa3igmx' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/qqa3igmx</a><br> View project at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250424_194725-qqa3igmx/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run qqa3igmx errored:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-5f50d447e20c>\", line 17, in train_and_evaluate\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = BumbleBee.from_pretrained(model_type=config.init_from, override_args=model_config).to(device)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-9-adc9f781450b>\", line 164, in from_pretrained\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     assert sd_hf[k].shape[::-1] == sd[k].shape\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ~~^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'transformer.h.0.attn.c_attn.weight'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rqf9gn7n with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_from: gpt2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 0.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1.5\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Ignoring project 'customser_service_sentiment_analysis' when running a sweep."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis/wandb/run-20250424_194735-rqf9gn7n</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/rqf9gn7n' target=\"_blank\">run_24-04-2025_19-47-35</a></strong> to <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/rqf9gn7n' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/rqf9gn7n</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.3\n","number of parameters: 123.65M\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">run_24-04-2025_19-47-35</strong> at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/rqf9gn7n' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/rqf9gn7n</a><br> View project at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250424_194735-rqf9gn7n/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rqf9gn7n errored:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-5f50d447e20c>\", line 17, in train_and_evaluate\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = BumbleBee.from_pretrained(model_type=config.init_from, override_args=model_config).to(device)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-9-adc9f781450b>\", line 164, in from_pretrained\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     assert sd_hf[k].shape[::-1] == sd[k].shape\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ~~^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'transformer.h.0.attn.c_attn.weight'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mogysluh with config:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_from: gpt2\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_grad_norm: 1\n","\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Ignoring project 'customser_service_sentiment_analysis' when running a sweep."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/AdvDeepLearning/SentimentAnalysis/wandb/run-20250424_194745-mogysluh</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mogysluh' target=\"_blank\">run_24-04-2025_19-47-45</a></strong> to <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View sweep at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/sweeps/m3sq2xrg</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mogysluh' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mogysluh</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading weights from pretrained gpt: gpt2\n","forcing vocab_size=50257, block_size=1024, bias=True\n","overriding dropout rate to 0.3\n","number of parameters: 123.65M\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n","Attention used: CausalSelfAttention\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">run_24-04-2025_19-47-45</strong> at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mogysluh' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification/runs/mogysluh</a><br> View project at: <a href='https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification' target=\"_blank\">https://wandb.ai/adityar2-carnegie-mellon-university/sentiment_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20250424_194745-mogysluh/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run mogysluh errored:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-10-5f50d447e20c>\", line 17, in train_and_evaluate\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model = BumbleBee.from_pretrained(model_type=config.init_from, override_args=model_config).to(device)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-9-adc9f781450b>\", line 164, in from_pretrained\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     assert sd_hf[k].shape[::-1] == sd[k].shape\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                    ~~^^^\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m KeyError: 'transformer.h.0.attn.c_attn.weight'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n","\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n"]}],"source":["sweep_config = {\n","    'method': 'grid',\n","    'parameters': {\n","        'epochs': {\n","            'value': 30\n","        },\n","        'batch_size': {\n","            'values': [32]\n","        },\n","        'dropout': {\n","           'values': [0.3]\n","        },\n","        'learning_rate': {\n","            'values': [0.001, 0.0001]\n","        },\n","        'weight_decay': {\n","            'values': [0.1, 1.5]\n","        },\n","        'max_grad_norm': {\n","            'values': [0.5, 1.0]\n","        },\n","        'beta1': {\n","            'values': [0.9]\n","        },\n","        'beta2': {\n","            'values': [0.999]\n","        },\n","        'init_from': {\n","            'value': 'gpt2'\n","        },\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=project_name)\n","\n","wandb.agent(sweep_id=sweep_id, function=train_and_evaluate)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"aFqg1qeUohUC","executionInfo":{"status":"ok","timestamp":1745524070762,"user_tz":240,"elapsed":16,"user":{"displayName":"Aditya Ramesh","userId":"16724543894616987802"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["oLKR_qNAQrcL","UWZfDiBjoS0E"],"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}